{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0769c653-c939-433f-9222-f51bf6e7fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from collections import deque\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f46d3a-2a34-444e-a5c4-5c9d0075be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL SETUPS\n",
    "TEMPLATE_BANK_SIZE = 5\n",
    "NCC_THRESHOLD = 0.5\n",
    "template_bank = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b71cd1-7dda-400d-8923-3c2295a36586",
   "metadata": {},
   "source": [
    "##\n",
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1e229e-b8ff-4e93-b9d9-fef1e4ea0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_first_frame(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot read video.\")\n",
    "        cap.release()\n",
    "        return None, None, None\n",
    "    return cap, frame, ret\n",
    "\n",
    "def load_template(initial_template_path, frame_gray):\n",
    "    template = cv2.imread(initial_template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if template is None:\n",
    "        print(\"Template image not found or failed to load.\")\n",
    "        return None\n",
    "\n",
    "    coords = cv2.findNonZero(template)\n",
    "    if coords is None:\n",
    "        print(\"No non-zero pixels in template.\")\n",
    "        return None\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    cropped_template = frame_gray[y:y+h, x:x+w]\n",
    "    return cropped_template, (x, y, w, h)\n",
    "\n",
    "def setup_video_writer(output_path, frame_shape, fps):\n",
    "    frame_h, frame_w = frame_shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_w, frame_h))\n",
    "    print(f\"💾 Output video will be saved to: {output_path}\")\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243e057c-21bf-4162-af74-4544337ac8d8",
   "metadata": {},
   "source": [
    "##\n",
    "## Template Matching + Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823776e5-313e-4ff5-9913-7c1a88f8adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(frame_gray, template_coords, padding=10):\n",
    "    x, y, w, h = template_coords\n",
    "    x_start = max(0, x - padding)\n",
    "    y_start = max(0, y - padding)\n",
    "    x_end = min(frame_gray.shape[1], x + w + padding)\n",
    "    y_end = min(frame_gray.shape[0], y + h + padding)\n",
    "\n",
    "    patch = frame_gray[y_start:y_end, x_start:x_end]\n",
    "    patch_loc = (x_start, y_start)  # top-left of patch\n",
    "\n",
    "    return patch, patch_loc\n",
    "\n",
    "def display_patch(patch, frame_idx, padding):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(patch, cmap='gray')\n",
    "    plt.title(f\"Patch (Frame {frame_idx}, Padding {padding})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def find_best_match(search_patch):\n",
    "    global template_bank\n",
    "    \n",
    "    best_score = -1\n",
    "    best_box = None\n",
    "    boxes = []\n",
    "    scores = []\n",
    "\n",
    "    for template in template_bank:\n",
    "        if search_patch.shape[0] < template.shape[0] or search_patch.shape[1] < template.shape[1]:\n",
    "            continue  # Skip if template is larger than the search patch\n",
    "\n",
    "        result = cv2.matchTemplate(search_patch, template, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        if max_val > best_score:\n",
    "            best_score = max_val\n",
    "            best_box = (*max_loc, template.shape[1], template.shape[0])  # (x, y, w, h)\n",
    "\n",
    "        boxes.append((*max_loc, template.shape[1], template.shape[0]))\n",
    "        scores.append(max_val)\n",
    "\n",
    "    if best_box is None:\n",
    "        best_box = (0, 0, 0, 0)\n",
    "\n",
    "    return boxes, scores, best_score\n",
    "\n",
    "\n",
    "def update_template_from_box(frame_gray, box):\n",
    "    x, y, w, h = box\n",
    "    new_template = frame_gray[y:y+h, x:x+w]\n",
    "    coords = cv2.findNonZero(new_template)\n",
    "    if coords is not None:\n",
    "        x_, y_, w_, h_ = cv2.boundingRect(coords)\n",
    "        return new_template[y_:y_+h_, x_:x_+w_]\n",
    "    return new_template\n",
    "\n",
    "def add_to_template_bank(patch):\n",
    "    global template_bank\n",
    "    \n",
    "    template_bank.append(patch)\n",
    "    if len(template_bank) > TEMPLATE_BANK_SIZE:\n",
    "        template_bank.pop(0)\n",
    "\n",
    "def apply_nms(boxes, scores, threshold, nms_thresh):\n",
    "    if not boxes:\n",
    "        return []\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, threshold, nms_thresh)\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "\n",
    "    # Flatten indices to list of integers\n",
    "    return [i[0] if isinstance(i, (list, np.ndarray)) else i for i in indices]\n",
    "\n",
    "#================================================#\n",
    "#======= FOR TEMPLATE BANK VISUALIZATION ========#\n",
    "#================================================#\n",
    "\n",
    "def get_template_index(template, template_bank):\n",
    "    for i, t in enumerate(template_bank):\n",
    "        if np.array_equal(t, template):\n",
    "            return i\n",
    "    return None  # Not found\n",
    "\n",
    "def visualize_template_bank(template_bank, current_index=None, max_per_row=5, figsize=(15, 5), cmap='gray'):\n",
    "    n = len(template_bank)\n",
    "    if n == 0:\n",
    "        print(\"⚠️ Template bank is empty.\")\n",
    "        return\n",
    "\n",
    "    cols = min(n, max_per_row)\n",
    "    rows = (n + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, template in enumerate(template_bank):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(template, cmap=cmap)\n",
    "        title = f\"Template {i}\"\n",
    "        if i == current_index:\n",
    "            # Highlight current template with red title and border\n",
    "            title += \" (Current)\"\n",
    "            ax.set_title(title, color='red')\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(2)\n",
    "        else:\n",
    "            ax.set_title(title)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4df15-b7cf-4af0-96e6-15c8c56f3638",
   "metadata": {},
   "source": [
    "##\n",
    "## Main Tracking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bd6f64-ef3f-4503-bf7b-042d440eba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tracking_box(frame, box):\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "\n",
    "def display_frame(frame, frame_idx):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.title(f\"Frame {frame_idx}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def template_difference(template1, template2, threshold=0.2):\n",
    "    if template1.shape != template2.shape:\n",
    "        return True  # treat different shape as significantly different\n",
    "    diff = np.mean((template1.astype(np.float32) - template2.astype(np.float32)) ** 2)\n",
    "    norm = np.mean(template1.astype(np.float32) ** 2)\n",
    "    nmse = diff / (norm + 1e-8)\n",
    "    return nmse > threshold\n",
    "\n",
    "def dynamic_template_matching(video_path, initial_template_path,\n",
    "                              output_path=\"../../outputs/dttm_output.mp4\",\n",
    "                              threshold=0.7, nms_thresh=0.3):\n",
    "    global template_bank\n",
    "    \n",
    "    padding = 10\n",
    "    max_padding = 50\n",
    "    min_padding = 5\n",
    "    padding_step = 5\n",
    "    \n",
    "    cap, frame, ret = read_video_first_frame(video_path)\n",
    "    if not ret:\n",
    "        return\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    template, template_coords = load_template(initial_template_path, frame_gray)\n",
    "    if template is None:\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    add_to_template_bank(template)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    out = setup_video_writer(output_path, frame.shape, fps)\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        if frame_idx != 0:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Video ended.\")\n",
    "                break\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        search_patch, patch_loc = get_patch(frame_gray, template_coords, padding)\n",
    "\n",
    "        '''\n",
    "        FOR PATCH VISUALIZATION\n",
    "        display_patch(search_patch, frame_idx, padding)\n",
    "        '''\n",
    "        boxes, scores, max_val = find_best_match(search_patch)\n",
    "        \n",
    "        print(f\"[Frame {frame_idx}] Max match score: {max_val:.3f}\")\n",
    "\n",
    "        indices = apply_nms(boxes, scores, threshold, nms_thresh)\n",
    "        if indices:\n",
    "            padding = max(min_padding, padding - padding_step)\n",
    "            best_idx = indices[0]\n",
    "            best_box = boxes[best_idx]\n",
    "\n",
    "            px, py = patch_loc\n",
    "            global_box = (best_box[0] + px, best_box[1] + py, best_box[2], best_box[3])\n",
    "\n",
    "            print(f\"  ↪ Object tracked at {global_box}\")\n",
    "            draw_tracking_box(frame, global_box)\n",
    "\n",
    "            new_template = update_template_from_box(frame_gray, global_box)\n",
    "            if new_template is not None and template_difference(new_template, template, threshold=0.2):\n",
    "                template = new_template\n",
    "                template_coords = global_box\n",
    "                add_to_template_bank(template)\n",
    "                print(\"  ↪ Template updated and added to bank.\\n\")\n",
    "            else:\n",
    "                print(\"  ↪ Template not different enough, skipped.\\n\")\n",
    "        else:\n",
    "            padding = min(max_padding, padding + padding_step)\n",
    "            print(\"  ⚠️ No match above threshold or NMS removed all boxes.\\n\")\n",
    "\n",
    "        '''\n",
    "        FOR TEMPLATE BANK VISUALIZATION\n",
    "        current_template_index = get_template_index(template, template_bank)\n",
    "        visualize_template_bank(template_bank, current_index=current_template_index)\n",
    "        '''\n",
    "        \n",
    "        out.write(frame)\n",
    "        display_frame(frame, frame_idx)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"🎥 Video saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219e209c-4f0b-4a52-ab1e-e31c68fdaa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Output video will be saved to: ../../outputs/dttm_output.mp4\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\templmatch.cpp:588: error: (-215:Assertion failed) corr.rows <= img.rows + templ.rows - 1 && corr.cols <= img.cols + templ.cols - 1 in function 'cv::crossCorr'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mvideo_path = \"../../data/DAVIS/videos/bear.mp4\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mtemplate_path = \"../../outputs/segmented/bear_segmented.png\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../outputs/dttm_output.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdynamic_template_matching\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_template_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemplate_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Matching confidence\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnms_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# NMS IoU threshold\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 63\u001b[0m, in \u001b[0;36mdynamic_template_matching\u001b[1;34m(video_path, initial_template_path, output_path, threshold, nms_thresh)\u001b[0m\n\u001b[0;32m     57\u001b[0m search_patch, patch_loc \u001b[38;5;241m=\u001b[39m get_patch(frame_gray, template_coords, padding)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mFOR PATCH VISUALIZATION\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mdisplay_patch(search_patch, frame_idx, padding)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m boxes, scores, max_val \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_patch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Frame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Max match score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m indices \u001b[38;5;241m=\u001b[39m apply_nms(boxes, scores, threshold, nms_thresh)\n",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m, in \u001b[0;36mfind_best_match\u001b[1;34m(search_patch)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m search_patch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m template\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m search_patch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m template\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip if template is larger than the search patch\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatchTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_patch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTM_CCOEFF_NORMED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m min_val, max_val, min_loc, max_loc \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mminMaxLoc(result)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_val \u001b[38;5;241m>\u001b[39m best_score:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.12.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\templmatch.cpp:588: error: (-215:Assertion failed) corr.rows <= img.rows + templ.rows - 1 && corr.cols <= img.cols + templ.cols - 1 in function 'cv::crossCorr'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_path = \"../../videos/ficen_trimmed.mp4\"\n",
    "template_path = \"../../outputs/segmented/ficen_trimmed_segmented.png\"\n",
    "'''\n",
    "video_path = \"../../data/DAVIS/videos/bear.mp4\"\n",
    "template_path = \"../../outputs/segmented/bear_segmented.png\"\n",
    "'''\n",
    "output_path = \"../../outputs/dttm_output.mp4\"\n",
    "\n",
    "dynamic_template_matching(\n",
    "    video_path=video_path,\n",
    "    initial_template_path=template_path,\n",
    "    output_path=output_path,\n",
    "    threshold=0.3,     # Matching confidence\n",
    "    nms_thresh=0.3     # NMS IoU threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5e5b9-c48a-4c7e-aef1-50431787a976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25e192-640e-4c5e-984d-7f60dacb9ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07b726-f864-42e8-8aa0-932a40602cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc97f1-c3b8-4d59-99d9-6f1b500d81be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b10af0-c7b5-4404-ab1c-f1c1ae6dd288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd1b02-04d2-4132-b526-9360abd686a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
