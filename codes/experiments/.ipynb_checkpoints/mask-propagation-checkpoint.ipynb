{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea63688-01f0-4819-9878-0e00b577c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5953e6d4-402b-4a2d-b6a5-8352e3b865b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL SETUPS\n",
    "TEMPLATE_BANK_SIZE = 5\n",
    "NCC_THRESHOLD = 0.5\n",
    "template_bank = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b236a83-21b9-44aa-bd64-bb710e8c69e2",
   "metadata": {},
   "source": [
    "##\n",
    "## Localization: Template Matching + Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f632956a-eebc-40bf-8b3e-ad21dafd8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_ncc_fft(search_image, template, mask):\n",
    "    \"\"\"\n",
    "    Compute masked normalized cross-correlation (NCC) between a search image and a template\n",
    "    using FFT-based convolution for efficiency.\n",
    "\n",
    "    Args:\n",
    "        search_image (np.ndarray): Grayscale search region image of shape (H, W).\n",
    "        template (np.ndarray): Grayscale template image of shape (h, w).\n",
    "        mask (np.ndarray): Binary mask of same shape as template; 1 indicates valid pixels,\n",
    "                           0 indicates pixels to ignore in matching.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            ncc_map (np.ndarray): Valid NCC map of shape (H - h + 1, W - w + 1).\n",
    "            max_val (float): Maximum NCC score found.\n",
    "            max_loc (tuple): (x, y) location of the maximum NCC score in ncc_map.\n",
    "    \"\"\"\n",
    "    # Convert inputs to float32 for numerical precision and FFT compatibility\n",
    "    search_f = search_image.astype(np.float32)\n",
    "    template_f = template.astype(np.float32)\n",
    "    mask_f = mask.astype(np.float32)\n",
    "\n",
    "    H, W = search_f.shape\n",
    "    h, w = template_f.shape\n",
    "\n",
    "    # Prepare padded arrays matching search image size\n",
    "    template_masked = template_f * mask_f\n",
    "    padded_template = np.zeros_like(search_f)\n",
    "    padded_mask = np.zeros_like(search_f)\n",
    "    padded_template[:h, :w] = template_masked\n",
    "    padded_mask[:h, :w] = mask_f\n",
    "\n",
    "    # Compute FFTs\n",
    "    fft_search = fft2(search_f)\n",
    "    fft_template = fft2(padded_template)\n",
    "    fft_mask = fft2(padded_mask)\n",
    "    fft_search_sq = fft2(search_f ** 2)\n",
    "\n",
    "    # Compute numerator and local sums via inverse FFT\n",
    "    numerator = ifft2(fft_search * np.conj(fft_template)).real\n",
    "    sum_search = ifft2(fft_search * np.conj(fft_mask)).real\n",
    "    sum_search_sq = ifft2(fft_search_sq * np.conj(fft_mask)).real\n",
    "    sum_mask = ifft2(fft_mask * np.conj(fft_mask)).real\n",
    "\n",
    "    # Precompute template sums\n",
    "    sum_template = np.sum(template_masked)\n",
    "    sum_template_sq = np.sum(template_masked ** 2)\n",
    "\n",
    "    # Compute denominator for NCC formula\n",
    "    denom = (sum_template_sq - (sum_template ** 2) / (sum_mask + 1e-8)) * \\\n",
    "            (sum_search_sq - (sum_search ** 2) / (sum_mask + 1e-8))\n",
    "    denom = np.maximum(denom, 0)\n",
    "    denom = np.sqrt(denom)\n",
    "\n",
    "    # Compute normalized cross-correlation map\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ncc = (numerator - (sum_search * sum_template / (sum_mask + 1e-8))) / denom\n",
    "        ncc[sum_mask < 1] = 0  # Invalidate locations with insufficient mask support\n",
    "\n",
    "    # Extract valid NCC region (where template fully fits inside search image)\n",
    "    valid_h = H - h + 1\n",
    "    valid_w = W - w + 1\n",
    "    ncc_valid = ncc[:valid_h, :valid_w]\n",
    "\n",
    "    # Find max NCC value and location\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(ncc_valid)\n",
    "    return ncc_valid, max_val, max_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f088c49f-ae6a-40c7-b966-74538e49bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(frame_gray, template_coords, padding=10):\n",
    "    \"\"\"\n",
    "    Extract a padded region (patch) from a grayscale frame.\n",
    "\n",
    "    Args:\n",
    "        frame_gray (np.ndarray): Grayscale frame image.\n",
    "        template_coords (tuple): Bounding box (x, y, w, h) of the template.\n",
    "        padding (int): Number of pixels to pad around the box.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (patch image, top-left patch coordinates)\n",
    "    \"\"\"\n",
    "    x, y, w, h = template_coords\n",
    "    x_start = max(0, x - padding)\n",
    "    y_start = max(0, y - padding)\n",
    "    x_end = min(frame_gray.shape[1], x + w + padding)\n",
    "    y_end = min(frame_gray.shape[0], y + h + padding)\n",
    "    return frame_gray[y_start:y_end, x_start:x_end], (x_start, y_start)\n",
    "\n",
    "\n",
    "def display_patch(patch, frame_idx, padding):\n",
    "    \"\"\"\n",
    "    Display a grayscale patch with annotation.\n",
    "\n",
    "    Args:\n",
    "        patch (np.ndarray): Image patch.\n",
    "        frame_idx (int): Index of the frame.\n",
    "        padding (int): Padding used to extract the patch.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(patch, cmap='gray')\n",
    "    plt.title(f\"Patch (Frame {frame_idx}, Padding {padding})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def rescale(template, template_mask, scale):\n",
    "    \"\"\"\n",
    "    Rescale both template and its mask by a given factor.\n",
    "\n",
    "    Args:\n",
    "        template (np.ndarray): Template image.\n",
    "        template_mask (np.ndarray): Binary mask for the template.\n",
    "        scale (float): Scaling factor.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (rescaled template, rescaled mask)\n",
    "    \"\"\"\n",
    "    new_w = max(1, int(template.shape[1] * scale))\n",
    "    new_h = max(1, int(template.shape[0] * scale))\n",
    "    scaled_template = cv2.resize(template, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    scaled_mask = cv2.resize(template_mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "    return scaled_template, scaled_mask\n",
    "\n",
    "\n",
    "def evaluate_templates(min_similarity, search_patch, scale, best_score, best_box,\n",
    "                       best_template, best_mask, best_scale, all_boxes, all_scores):\n",
    "    \"\"\"\n",
    "    Evaluate all templates in the bank at a given scale and update best match if needed.\n",
    "\n",
    "    Args:\n",
    "        min_similarity (float): Score threshold to consider updating the bank.\n",
    "        search_patch (np.ndarray): Grayscale image region to match against.\n",
    "        scale (float): Scale to apply to templates.\n",
    "        best_score (float): Current best similarity score.\n",
    "        best_box (tuple): Current best bounding box.\n",
    "        best_template (np.ndarray): Current best template image.\n",
    "        best_mask (np.ndarray): Current best template mask.\n",
    "        best_scale (float): Current best matching scale.\n",
    "        all_boxes (list): Accumulator for all bounding boxes.\n",
    "        all_scores (list): Accumulator for all scores.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (template_updated, best_score, best_box, best_template, best_mask,\n",
    "                best_scale, all_boxes, all_scores)\n",
    "    \"\"\"\n",
    "    H, W = search_patch.shape\n",
    "    template_updated = False\n",
    "\n",
    "    for template_img, template_mask in template_bank:\n",
    "        if scale != 1.0:\n",
    "            template_img, template_mask = rescale(template_img, template_mask, scale)\n",
    "\n",
    "        h, w = template_img.shape\n",
    "        if H < h or W < w:\n",
    "            continue\n",
    "\n",
    "        _, score, loc = masked_ncc_fft(search_patch, template_img, template_mask)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_box = (*loc, w, h)\n",
    "            best_template = template_img\n",
    "            best_mask = template_mask\n",
    "            best_scale = scale\n",
    "\n",
    "        all_boxes.append((*loc, w, h))\n",
    "        all_scores.append(score)\n",
    "\n",
    "        if score > min_similarity and scale != 1.0:\n",
    "            if best_template is not None and best_mask is not None:\n",
    "                add_to_template_bank(best_template, best_mask)\n",
    "                template_updated = True\n",
    "            break\n",
    "\n",
    "    return template_updated, best_score, best_box, best_template, best_mask, best_scale, all_boxes, all_scores\n",
    "\n",
    "\n",
    "def find_best_match(search_patch, min_similarity=0.8, scales=[0.9, 0.95, 1.05, 1.1]):\n",
    "    \"\"\"\n",
    "    Find the best matching template (multi-scale) within a search patch.\n",
    "\n",
    "    Args:\n",
    "        search_patch (np.ndarray): Grayscale region to match against.\n",
    "        min_similarity (float): Minimum similarity threshold to avoid scaling.\n",
    "        scales (list): List of scale factors to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (template_updated, all_boxes, all_scores, best_score,\n",
    "                best_box, best_template, best_mask, best_scale)\n",
    "    \"\"\"\n",
    "    best_score = -1\n",
    "    best_box = None\n",
    "    best_template = None\n",
    "    best_mask = None\n",
    "    best_scale = 1.0\n",
    "    all_boxes, all_scores = [], []\n",
    "\n",
    "    result = evaluate_templates(min_similarity, search_patch, 1.0, best_score,\n",
    "                                best_box, best_template, best_mask, best_scale,\n",
    "                                all_boxes, all_scores)\n",
    "    (template_updated, best_score, best_box, best_template,\n",
    "     best_mask, best_scale, all_boxes, all_scores) = result\n",
    "\n",
    "    if best_score < min_similarity:\n",
    "        for scale in scales:\n",
    "            result = evaluate_templates(min_similarity, search_patch, scale, best_score,\n",
    "                                        best_box, best_template, best_mask, best_scale,\n",
    "                                        all_boxes, all_scores)\n",
    "            (template_updated, best_score, best_box, best_template,\n",
    "             best_mask, best_scale, all_boxes, all_scores) = result\n",
    "\n",
    "    if best_box is None:\n",
    "        best_box = (0, 0, 0, 0)\n",
    "\n",
    "    return template_updated, all_boxes, all_scores, best_score, best_box, best_template, best_mask, best_scale\n",
    "\n",
    "\n",
    "def update_template_from_box(frame_gray, box):\n",
    "    \"\"\"\n",
    "    Create a new template and binary mask from a specified region.\n",
    "\n",
    "    Args:\n",
    "        frame_gray (np.ndarray): Grayscale frame image.\n",
    "        box (tuple): Bounding box (x, y, w, h) for the region.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (cropped template, binary mask from Otsu thresholding)\n",
    "    \"\"\"\n",
    "    x, y, w, h = box\n",
    "    new_template = frame_gray[y:y+h, x:x+w]\n",
    "    _, new_mask = cv2.threshold(new_template, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return new_template, new_mask\n",
    "\n",
    "\n",
    "def add_to_template_bank(template, mask, max_size=TEMPLATE_BANK_SIZE):\n",
    "    \"\"\"\n",
    "    Add a new template to the global template bank, maintaining a fixed max size.\n",
    "\n",
    "    Args:\n",
    "        template (np.ndarray): Template image to store.\n",
    "        mask (np.ndarray): Corresponding binary mask.\n",
    "        max_size (int): Maximum size of the bank.\n",
    "    \"\"\"\n",
    "    global template_bank\n",
    "    template_bank.append((template, mask))\n",
    "    if len(template_bank) > max_size:\n",
    "        template_bank.pop(0)\n",
    "\n",
    "\n",
    "def apply_nms(boxes, scores, threshold, nms_thresh):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression to a set of bounding boxes and scores.\n",
    "\n",
    "    Args:\n",
    "        boxes (list): List of bounding boxes.\n",
    "        scores (list): Confidence scores corresponding to the boxes.\n",
    "        threshold (float): Score threshold for consideration.\n",
    "        nms_thresh (float): Overlap threshold for NMS.\n",
    "\n",
    "    Returns:\n",
    "        list: Indices of selected boxes after NMS.\n",
    "    \"\"\"\n",
    "    if not boxes:\n",
    "        return []\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, threshold, nms_thresh)\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "\n",
    "    return [i[0] if isinstance(i, (list, np.ndarray)) else i for i in indices]\n",
    "\n",
    "\n",
    "def get_template_index(template, template_bank):\n",
    "    \"\"\"\n",
    "    Get index of a template in the bank using array equality.\n",
    "\n",
    "    Args:\n",
    "        template (np.ndarray): Template to search for.\n",
    "        template_bank (list): List of (template, mask) tuples.\n",
    "\n",
    "    Returns:\n",
    "        int or None: Index if found, else None.\n",
    "    \"\"\"\n",
    "    for i, (t, _) in enumerate(template_bank):\n",
    "        if np.array_equal(t, template):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "\n",
    "def visualize_template_bank(template_bank, current_index=None, max_per_row=5,\n",
    "                            figsize=(15, 5), cmap='gray'):\n",
    "    \"\"\"\n",
    "    Visualize all templates and masks in the bank using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        template_bank (list): List of (template, mask) tuples.\n",
    "        current_index (int): Index to highlight (optional).\n",
    "        max_per_row (int): Max number of images per row.\n",
    "        figsize (tuple): Figure size for display.\n",
    "        cmap (str): Color map for grayscale display.\n",
    "    \"\"\"\n",
    "    n = len(template_bank)\n",
    "    if n == 0:\n",
    "        print(\"⚠️ Template bank is empty.\")\n",
    "        return\n",
    "\n",
    "    cols = min(n, max_per_row)\n",
    "    rows = (n + cols - 1) // cols\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, (template, mask) in enumerate(template_bank):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "\n",
    "        if mask.dtype != np.uint8:\n",
    "            mask = mask.astype(np.uint8)\n",
    "        if mask.shape != template.shape:\n",
    "            mask = cv2.resize(mask, (template.shape[1], template.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        masked = cv2.bitwise_and(template, template, mask=mask)\n",
    "        overlay = np.stack([masked]*3, axis=-1)\n",
    "        overlay[mask == 0] = [255, 0, 0]\n",
    "\n",
    "        ax.imshow(overlay)\n",
    "        title = f\"Template {i}\"\n",
    "        if i == current_index:\n",
    "            title += \" (Current)\"\n",
    "            ax.set_title(title, color='red')\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor('red')\n",
    "                spine.set_linewidth(2)\n",
    "        else:\n",
    "            ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d6060-44c1-4f97-8483-522ebbf128b2",
   "metadata": {},
   "source": [
    "##\n",
    "## Mask Refinement: Similarity with Previous Foreground (nanti separate file???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9e8f08f-752b-4839-beac-5ef1a6e45f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_mask(frame_roi_gray, template_gray, template_mask,\n",
    "                similarity_threshold=0.15, dissimilarity_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Produce a rough initial mask by comparing grayscale values between\n",
    "    current ROI and template. Used as unary term for CRF.\n",
    "\n",
    "    Args:\n",
    "        frame_roi_gray (np.ndarray): Grayscale current ROI.\n",
    "        template_gray (np.ndarray): Grayscale template.\n",
    "        template_mask (np.ndarray): Binary mask for template (1=fg).\n",
    "        similarity_threshold (float): Intensity difference for foreground match.\n",
    "        dissimilarity_threshold (float): Threshold to suppress clear background.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Rough binary mask (uint8, values 0 or 1).\n",
    "    \"\"\"\n",
    "    # Resize template and mask to match current ROI\n",
    "    h, w = frame_roi_gray.shape\n",
    "    template_gray = cv2.resize(template_gray, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    template_mask = cv2.resize(template_mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Normalize\n",
    "    frame_norm = frame_roi_gray.astype(np.float32) / 255.0\n",
    "    template_norm = template_gray.astype(np.float32) / 255.0\n",
    "\n",
    "    # Compute difference\n",
    "    diff = np.abs(frame_norm - template_norm)\n",
    "\n",
    "    # Foreground if similar *and* was previously foreground\n",
    "    fg = ((diff < similarity_threshold) & (template_mask > 0)).astype(np.uint8)\n",
    "\n",
    "    # Suppress background if very dissimilar\n",
    "    bg = (diff > dissimilarity_threshold).astype(np.uint8)\n",
    "    fg[bg == 1] = 0\n",
    "\n",
    "    return fg\n",
    "\n",
    "\n",
    "# ========== USE CRF ============ #\n",
    "def crf_refine(frame_bgr, mask):\n",
    "    \"\"\"\n",
    "    Refine binary mask with DenseCRF.\n",
    "    \n",
    "    Args:\n",
    "        frame_bgr (np.ndarray): BGR image (uint8).\n",
    "        mask (np.ndarray): Binary mask (0 or 1).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Refined binary mask (0 or 1).\n",
    "    \"\"\"\n",
    "    frame_bgr = frame_bgr.copy()\n",
    "    \n",
    "    h, w = mask.shape\n",
    "    n_labels = 2  # background=0, foreground=1\n",
    "\n",
    "    labels = mask.astype(np.uint32)\n",
    "\n",
    "    d = dcrf.DenseCRF2D(w, h, n_labels)\n",
    "    unary = unary_from_labels(labels, n_labels, gt_prob=0.7, zero_unsure=False)\n",
    "    d.setUnaryEnergy(unary)\n",
    "\n",
    "    # Smoothness\n",
    "    d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "\n",
    "    # Color-based edge alignment\n",
    "    d.addPairwiseBilateral(sxy=50, srgb=13, rgbim=frame_bgr, compat=10)\n",
    "\n",
    "    Q = d.inference(5)\n",
    "    refined = np.argmax(Q, axis=0).reshape((h, w))\n",
    "\n",
    "    return refined.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c852a0-c7b1-4a35-8605-d08a44f4aa80",
   "metadata": {},
   "source": [
    "##\n",
    "## Background Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58dc0ef5-92a5-4d6a-bc1b-55e2639665d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_background(image: np.ndarray, mask: np.ndarray, ksize=(33, 33), sigma=0, feather_radius=15) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Blurs the background of the image while keeping the foreground sharp,\n",
    "    using a feathered mask for smooth blending.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): RGB image (H, W, 3).\n",
    "        mask (np.ndarray): Binary mask (H, W), foreground=1 or 255.\n",
    "        ksize (tuple, optional): Kernel size for Gaussian blur. Defaults to (33, 33).\n",
    "        sigma (int, optional): Gaussian blur sigma for background blur. Defaults to 0.\n",
    "        feather_radius (int, optional): Radius in pixels to feather mask edges. Defaults to 15.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image with blurred background and feathered transition.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize mask to 0..1 float\n",
    "    mask_norm = (mask > 0).astype(np.float32)\n",
    "\n",
    "    # Feather mask by applying Gaussian blur on the binary mask edges\n",
    "    # This creates a smooth transition (values between 0 and 1)\n",
    "    feathered_mask = cv2.GaussianBlur(mask_norm, (feather_radius*2+1, feather_radius*2+1), 0)\n",
    "\n",
    "    # Blur the whole image\n",
    "    blurred = cv2.GaussianBlur(image, ksize, sigma)\n",
    "\n",
    "    # Blend images using the feathered mask as weights per pixel\n",
    "    # Foreground = feathered_mask close to 1 -> mostly sharp image\n",
    "    # Background = feathered_mask close to 0 -> mostly blurred image\n",
    "    feathered_mask_3c = np.repeat(feathered_mask[:, :, None], 3, axis=2)\n",
    "\n",
    "    combined = (image.astype(np.float32) * feathered_mask_3c +\n",
    "                blurred.astype(np.float32) * (1 - feathered_mask_3c))\n",
    "\n",
    "    return combined.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747708e-0241-48c6-a360-04ab6ab7459f",
   "metadata": {},
   "source": [
    "##\n",
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fd8b84c-0e5d-4676-89fa-d1dacda2587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_first_frame(video_path):\n",
    "    \"\"\"\n",
    "    Read the first frame of a video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (cv2.VideoCapture object, first frame as np.ndarray, success flag as bool).\n",
    "               Returns (None, None, None) if the video cannot be read.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot read video.\")\n",
    "        cap.release()\n",
    "        return None, None, None\n",
    "    return cap, frame, ret\n",
    "\n",
    "\n",
    "def load_template(initial_template_path, frame_gray):\n",
    "    \"\"\"\n",
    "    Load and extract the non-zero region of a grayscale template from a frame.\n",
    "\n",
    "    Args:\n",
    "        initial_template_path (str): Path to the grayscale template image.\n",
    "        frame_gray (np.ndarray): Grayscale frame from which to extract the region.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (cropped region from frame, cropped template, bounding box as (x, y, w, h)).\n",
    "               Returns None if template cannot be loaded or contains no non-zero pixels.\n",
    "    \"\"\"\n",
    "    template = cv2.imread(initial_template_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if template is None:\n",
    "        print(\"Template image not found or failed to load.\")\n",
    "        return None\n",
    "\n",
    "    coords = cv2.findNonZero(template)\n",
    "    if coords is None:\n",
    "        print(\"No non-zero pixels in template.\")\n",
    "        return None\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    return frame_gray[y:y+h, x:x+w], template[y:y+h, x:x+w], (x, y, w, h)\n",
    "\n",
    "\n",
    "def setup_video_writer(output_path, frame_shape, fps):\n",
    "    \"\"\"\n",
    "    Initialize a video writer to save processed frames.\n",
    "\n",
    "    Args:\n",
    "        output_path (str): File path to save the output video.\n",
    "        frame_shape (tuple): Shape of the video frame (height, width, channels).\n",
    "        fps (float): Frames per second for the output video.\n",
    "\n",
    "    Returns:\n",
    "        cv2.VideoWriter: Configured video writer object.\n",
    "    \"\"\"\n",
    "    frame_h, frame_w = frame_shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_w, frame_h))\n",
    "    print(f\"💾 Output video will be saved to: {output_path}\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3875ec-122c-47f8-93a8-3996f6cd59f9",
   "metadata": {},
   "source": [
    "##\n",
    "## Main Mask Propagation Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "420f223c-5974-4d47-8bc1-91aad77310a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_foreground(frame, mask, color=(0, 0, 255), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Overlay a semi-transparent color highlight on the foreground mask.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): BGR image.\n",
    "        mask (np.ndarray): Binary mask where foreground = 1 or 255.\n",
    "        color (tuple): BGR color to overlay (default is red).\n",
    "        alpha (float): Opacity of the overlay (0 = transparent, 1 = solid).\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Frame with foreground highlighted.\n",
    "    \"\"\"\n",
    "    if mask.max() == 1:\n",
    "        mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Create colored overlay\n",
    "    overlay = np.zeros_like(frame, dtype=np.uint8)\n",
    "    overlay[:] = color\n",
    "\n",
    "    # Create 3-channel mask\n",
    "    mask_3ch = cv2.merge([mask] * 3)\n",
    "\n",
    "    # Blend only where mask is non-zero\n",
    "    frame_highlighted = frame.copy()\n",
    "    frame_highlighted = np.where(mask_3ch > 0,\n",
    "                                 cv2.addWeighted(frame, 1 - alpha, overlay, alpha, 0),\n",
    "                                 frame)\n",
    "    return frame_highlighted\n",
    "\n",
    "\n",
    "def draw_tracking_box(frame, box):\n",
    "    \"\"\"\n",
    "    Draw a yellow rectangle on the frame at the specified bounding box.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Image frame to draw on.\n",
    "        box (tuple): Bounding box as (x, y, w, h).\n",
    "    \"\"\"\n",
    "    x, y, w, h = box\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "def display_frame(frame, frame_idx):\n",
    "    \"\"\"\n",
    "    Display a single video frame using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): BGR image frame to display.\n",
    "        frame_idx (int): Index of the current frame.\n",
    "    \"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.title(f\"Frame {frame_idx}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def template_difference(template1, template2, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Determine if two templates are significantly different based on NMSE.\n",
    "\n",
    "    Args:\n",
    "        template1 (np.ndarray): First grayscale template.\n",
    "        template2 (np.ndarray): Second grayscale template.\n",
    "        threshold (float): Normalized mean square error threshold.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if templates are different beyond threshold.\n",
    "    \"\"\"\n",
    "    if template1.shape != template2.shape:\n",
    "        return True\n",
    "    diff = np.mean((template1.astype(np.float32) - template2.astype(np.float32)) ** 2)\n",
    "    norm = np.mean(template1.astype(np.float32) ** 2)\n",
    "    nmse = diff / (norm + 1e-8)\n",
    "    return nmse > threshold\n",
    "\n",
    "\n",
    "def dynamic_template_matching(video_path, initial_template_path,\n",
    "                              output_path=\"../../outputs/dttm_output.mp4\",\n",
    "                              threshold=0.7, nms_thresh=0.3,\n",
    "                              similarity_threshold=0.3, num_superpixels=200,\n",
    "                              blur_kernel=(25, 25), blur_sigma=0, feather_radius=15):\n",
    "    \"\"\"\n",
    "    Perform dynamic template matching with mask refinement and background blur.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        initial_template_path (str): Path to the segmented template image.\n",
    "        output_path (str): Path to save the output video.\n",
    "        threshold (float): Score threshold for match filtering.\n",
    "        nms_thresh (float): Non-maximum suppression IoU threshold.\n",
    "        similarity_threshold (float): Threshold for pixel similarity in refinement.\n",
    "        num_superpixels (int): Number of superpixels for CRF refinement (unused in current scope).\n",
    "        blur_kernel (tuple): Kernel size for background blur.\n",
    "        blur_sigma (float): Sigma value for Gaussian blur.\n",
    "        feather_radius (int): Radius for feathering mask edges.\n",
    "    \"\"\"\n",
    "    padding, max_padding, min_padding, padding_step = 10, 50, 2, 3\n",
    "\n",
    "    cap, frame, ret = read_video_first_frame(video_path)\n",
    "    if not ret:\n",
    "        return\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    result = load_template(initial_template_path, frame_gray)\n",
    "    if result is None:\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    template_bg, template, template_coords = result\n",
    "    template_mask = (template > 0).astype(np.uint8)\n",
    "    add_to_template_bank(template, template_mask)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "    out = setup_video_writer(output_path, frame.shape, fps)\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        if frame_idx != 0:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"📽 Video ended.\")\n",
    "                break\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        search_patch, patch_loc = get_patch(frame_gray, template_coords, padding)\n",
    "        template_updated, boxes, scores, max_val, *_ = find_best_match(search_patch)\n",
    "        print(f\"[Frame {frame_idx}] Max match score: {max_val:.3f}\")\n",
    "\n",
    "        if template_updated:\n",
    "            print(\"new template scale\")\n",
    "            template, template_mask = template_bank[-1]\n",
    "\n",
    "        indices = apply_nms(boxes, scores, threshold, nms_thresh)\n",
    "        if indices:\n",
    "            padding = max(min_padding, padding - padding_step)\n",
    "            best_idx = indices[0]\n",
    "            best_box = boxes[best_idx]\n",
    "\n",
    "            px, py = patch_loc\n",
    "            global_box = (best_box[0] + px, best_box[1] + py, best_box[2], best_box[3])\n",
    "            print(f\"  ↪ Object tracked at {global_box}\")\n",
    "\n",
    "            x, y, w, h = global_box\n",
    "            frame_roi_gray = frame_gray[y:y+h, x:x+w]\n",
    "\n",
    "            initial_mask = refine_mask(\n",
    "                frame_roi_gray,\n",
    "                template,\n",
    "                template_mask,\n",
    "                similarity_threshold\n",
    "            )\n",
    "\n",
    "            roi_bgr = frame[y:y+h, x:x+w]\n",
    "            final_mask = crf_refine(roi_bgr, initial_mask)\n",
    "\n",
    "            template_mask_refined = final_mask\n",
    "\n",
    "            # Apply background blur with feathering\n",
    "            full_mask = np.pad(\n",
    "                template_mask_refined,\n",
    "                ((y, frame.shape[0]-y-h), (x, frame.shape[1]-x-w)),\n",
    "                mode='constant', constant_values=0\n",
    "            )\n",
    "            frame = blur_background(frame, full_mask, ksize=blur_kernel,\n",
    "                                    sigma=blur_sigma, feather_radius=feather_radius)\n",
    "            \n",
    "            frame = highlight_foreground(frame, full_mask, color=(0, 0, 255), alpha=0.4)\n",
    "\n",
    "            template_refined = cv2.bitwise_and(frame_roi_gray, frame_roi_gray, mask=template_mask_refined)\n",
    "            if template_difference(template, template_refined, threshold=0.2):\n",
    "                template = template_refined\n",
    "                template_mask = template_mask_refined\n",
    "                template_coords = global_box\n",
    "                add_to_template_bank(template, template_mask)\n",
    "                print(\"  ↪ Template updated with refined mask and added to bank.\\n\")\n",
    "            else:\n",
    "                print(\"  ↪ Template not updated — too similar to previous.\\n\")\n",
    "\n",
    "            prev_roi_gray = frame_roi_gray.copy()\n",
    "            prev_mask = template_mask_refined.copy()\n",
    "            prev_coords = global_box\n",
    "\n",
    "        else:\n",
    "            padding = min(max_padding, padding + padding_step)\n",
    "            print(\"  ⚠ No match above threshold or NMS removed all boxes.\\n\")\n",
    "\n",
    "        out.write(frame)\n",
    "        display_frame(frame, frame_idx)\n",
    "        frame_idx += 1\n",
    "\n",
    "        visualize_template_bank(template_bank)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"🎥 Video saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b969d15-e0bd-44c2-b86e-a1d852064661",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dynamic_template_matching' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mvideo_path = \"../../data/DAVIS/videos/kite-walk.mp4\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mtemplate_path = \"../../outputs/segmented/kite_walk_segmented.png\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     11\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../outputs/blurred/blur_output.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdynamic_template_matching\u001b[49m(\n\u001b[0;32m     14\u001b[0m     video_path\u001b[38;5;241m=\u001b[39mvideo_path,\n\u001b[0;32m     15\u001b[0m     initial_template_path\u001b[38;5;241m=\u001b[39mtemplate_path,\n\u001b[0;32m     16\u001b[0m     output_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m     17\u001b[0m     threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,     \u001b[38;5;66;03m# Matching confidence\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     nms_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m     \u001b[38;5;66;03m# NMS IoU threshold\u001b[39;00m\n\u001b[0;32m     19\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dynamic_template_matching' is not defined"
     ]
    }
   ],
   "source": [
    "template_bank = []\n",
    "\n",
    "\n",
    "video_path = \"../../data/personal/videos/clay.mp4\"\n",
    "template_path = \"../../outputs/segmented/clay_segmented.png\"\n",
    "'''\n",
    "video_path = \"../../data/DAVIS/videos/kite-walk.mp4\"\n",
    "template_path = \"../../outputs/segmented/kite_walk_segmented.png\"\n",
    "'''\n",
    "\n",
    "output_path = \"../../outputs/blurred/blur_output.mp4\"\n",
    "\n",
    "dynamic_template_matching(\n",
    "    video_path=video_path,\n",
    "    initial_template_path=template_path,\n",
    "    output_path=output_path,\n",
    "    threshold=0.3,     # Matching confidence\n",
    "    nms_thresh=0.3     # NMS IoU threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847833c-0899-4c14-9aa6-c793bb306737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440217e-927a-4ac2-bb72-f7f04cf08d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296d122-707b-40cb-b490-d0610edd904d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa29e21-c0a1-4a06-bd60-3356381534a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19740bc0-33b6-4ad2-aff5-6e503c9d1b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
